{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e03cb0f8-1376-438a-87d6-0f0018524bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import LSTM, RepeatVector, TimeDistributed, Dense\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import collections\n",
    "from random import shuffle\n",
    "import itertools\n",
    "from os import listdir\n",
    "import random\n",
    "import string\n",
    "import statistics\n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d9a31c1-ff4e-4132-a307-d78d2100c050",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'Weight on Bit (klbs)',\n",
    "    'Rotary RPM (RPM)',\n",
    "    'Total Pump Output (gal_per_min)',\n",
    "    'Rate Of Penetration (ft_per_hr)',\n",
    "    'Standpipe Pressure (psi)',\n",
    "    'Rotary Torque (kft_lb)', \n",
    "    'Hole Depth (feet)', \n",
    "    'Bit Depth (feet)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a72daff5-bb2f-4f29-b5d9-f657e789d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_windows(dataset, columns):\n",
    "    df = pd.read_csv(f\"Datasets\\\\MaskedAutoencoder\\\\{dataset}\")\n",
    "    df = df[columns]\n",
    "\n",
    "    base_mask = (\n",
    "        (df[\"Hole Depth (feet)\"].rolling(10000).mean().diff() > 0) &\n",
    "        (df[\"Hole Depth (feet)\"] == df[\"Bit Depth (feet)\"]) &\n",
    "        (df[\"Hole Depth (feet)\"] > 1000)\n",
    "    )\n",
    "    \n",
    "    window = 100       # Rolling window size\n",
    "    threshold = 0.3    # Keep if rolling average > threshold\n",
    "    \n",
    "    # Compute rolling average of the mask (convert to 0/1 first)\n",
    "    rolling_avg = base_mask.astype(float).rolling(window).mean()\n",
    "    \n",
    "    # Final mask based on rolling average threshold\n",
    "    final_mask = (rolling_avg > threshold).fillna(0)\n",
    "    \n",
    "    final_mask = final_mask.astype(float).rolling(20000).mean() > 0.6\n",
    "    \n",
    "    masked_hole_depth = df[\"Hole Depth (feet)\"].where(final_mask, np.nan)\n",
    "    \n",
    "    gap_threshold = 100  # maximum number of consecutive NaNs to merge segments\n",
    "    \n",
    "    # Identify indices of non-NaN values\n",
    "    not_nan_idx = masked_hole_depth[masked_hole_depth.notna()].index\n",
    "    \n",
    "    # Grouping non-NaN indices based on closeness\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    \n",
    "    for i, idx in enumerate(not_nan_idx):\n",
    "        if i == 0:\n",
    "            current_group.append(idx)\n",
    "            continue\n",
    "    \n",
    "        # Check gap from previous index\n",
    "        if idx - not_nan_idx[i-1] <= gap_threshold:\n",
    "            current_group.append(idx)\n",
    "        else:\n",
    "            groups.append(current_group)\n",
    "            current_group = [idx]\n",
    "    \n",
    "    # Append last group\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "\n",
    "    # Fix all NaNs\n",
    "    drilling_segments = [  ]\n",
    "    window_size = 100\n",
    "    for group in groups:\n",
    "        dfg = df.loc[group].copy()\n",
    "        \n",
    "        for col in dfg.columns:\n",
    "            if np.issubdtype(dfg[col].dtype, np.number):\n",
    "                series = dfg[col]      \n",
    "                rolling_mean = series.rolling(window=window_size, min_periods=1, center=True).mean()\n",
    "                dfg[col] = series.fillna(rolling_mean).bfill(  ).ffill()\n",
    "    \n",
    "        drilling_segments.append(dfg)\n",
    "    \n",
    "    # Min Max Normalization\n",
    "    global_min = pd.concat(drilling_segments).min()\n",
    "    global_max = pd.concat(drilling_segments).max()\n",
    "    \n",
    "    # Step 2: Normalize each dataframe\n",
    "    print(f\"Drilling Segments: {len(drilling_segments)}\")\n",
    "    normalized_drilling_segments = []\n",
    "    for df in drilling_segments:\n",
    "        normalized_df = (df - global_min) / (global_max - global_min)\n",
    "        normalized_drilling_segments.append(normalized_df)\n",
    "\n",
    "    window_size = 60 * 10  # 10 minutes\n",
    "\n",
    "    windows = []\n",
    "    count = 1\n",
    "    for df in normalized_drilling_segments:\n",
    "        print(f\"\\t{count}\")\n",
    "        count += 1\n",
    "        for i in range(len(df) - window_size + 1):\n",
    "            window = df.iloc[i:i + window_size]\n",
    "            windows.append(window.to_numpy())\n",
    "\n",
    "    print(f\"Windows: {len(windows):,}\".replace(',', ' ')) \n",
    "    print(f\"Windows per Segment: {len(windows) / len(drilling_segments):,.2f}\".replace(',', ' '))\n",
    "    \n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81ed19b3-8fee-4b2a-bf9d-93925474f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_data(data, MASKING_PERCENT=0.8):\n",
    "    masked_data = []\n",
    "    mask_indices_all = []\n",
    "    \n",
    "    last_printed = -1\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        arr = data[i]\n",
    "        \n",
    "        percentage = (i / len(data)) * 100\n",
    "        current_milestone = int(percentage / 1)\n",
    "        \n",
    "        if current_milestone > last_printed:\n",
    "            print(f\"{round(percentage, 4)}\")\n",
    "            last_printed = current_milestone\n",
    "    \n",
    "        # Convert to numpy array if needed\n",
    "        arr = np.array(arr, dtype=float)\n",
    "        \n",
    "        # Create a copy to avoid modifying original\n",
    "        masked_arr = arr.copy()\n",
    "        \n",
    "        # Get total number of elements\n",
    "        total_elements = arr.size\n",
    "        n_mask = int(total_elements * MASKING_PERCENT)\n",
    "        \n",
    "        # Generate random indices to mask\n",
    "        flat_indices = np.random.choice(total_elements, size=n_mask, replace=False)\n",
    "        \n",
    "        # Convert flat indices to 2D indices\n",
    "        mask_indices = np.unravel_index(flat_indices, arr.shape)\n",
    "        \n",
    "        # Apply mask (set to NaN)\n",
    "        masked_arr[mask_indices] = np.nan\n",
    "        \n",
    "        masked_data.append(masked_arr)\n",
    "        mask_indices_all.append(list(zip(mask_indices[0], mask_indices[1])))\n",
    "    \n",
    "    return masked_data, mask_indices_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6182e07c-0156-4180-b2c3-70dbbc8ca326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder training: 78B-32 1 sec data 27200701.csv, 27029986-3.csv\n",
    "# Task Header 1 (DAS Stickslip): 27029986-4.csv\n",
    "# Task Header 2 (Temp OUT (Degrees)): 27029986-5.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b7142e-8ece-47a0-95ab-311c27f332c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drilling Segments: 3\n",
      "\t1\n",
      "\t2\n",
      "\t3\n",
      "Windows: 131 072\n",
      "Windows per Segment: 43 690.67\n",
      "Drilling Segments: 9\n",
      "\t1\n",
      "\t2\n",
      "\t3\n",
      "\t4\n",
      "\t5\n",
      "\t6\n",
      "\t7\n",
      "\t8\n",
      "\t9\n",
      "Windows: 332 561\n",
      "Windows per Segment: 36 951.22\n",
      "Sampled 131 072 from each list\n",
      "Total windows: 262 144\n"
     ]
    }
   ],
   "source": [
    "windows1 = csv_to_windows(\"27029986-3.csv\", columns)\n",
    "windows2 = csv_to_windows(\"78B-32 1 sec data 27200701.csv\", columns)\n",
    "\n",
    "# Shuffle both lists\n",
    "random.seed(42)\n",
    "random.shuffle(windows1)\n",
    "random.shuffle(windows2)\n",
    "\n",
    "# Take the same amount from each (the minimum length)\n",
    "min_length = min(len(windows1), len(windows2))\n",
    "windows1_sampled = windows1[:min_length]\n",
    "windows2_sampled = windows2[:min_length]\n",
    "\n",
    "# Combine them\n",
    "windows = windows1_sampled + windows2_sampled\n",
    "\n",
    "# Shuffle the combined list\n",
    "random.shuffle(windows)\n",
    "\n",
    "print(f\"Sampled {min_length:,} from each list\".replace(',', ' '))\n",
    "print(f\"Total windows: {len(windows):,}\".replace(',', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fa2d00-47e3-46a3-ad90-b3ee040123dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0004\n",
      "2.0003\n",
      "3.0003\n"
     ]
    }
   ],
   "source": [
    "train_windows_y, test_windows_y = train_test_split(windows, test_size=0.2, random_state=42)\n",
    "train_windows_x = mask_data(train_windows_y, MASKING_PERCENT=0.8)\n",
    "test_windows_x = mask_data(test_windows_y, MASKING_PERCENT=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ede37-182a-43a4-8340-982433b5af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make model\n",
    "\n",
    "model = Sequential()\n",
    "model.add( LSTM(128, activation='tanh', input_shape=(train_windows[0].shape[0], train_windows[0].shape[1]), return_sequences=True ) )\n",
    "model.add( LSTM(64, activation='tanh', return_sequences=False ) )\n",
    "model.add( RepeatVector(train_windows[0].shape[0]) )\n",
    "model.add( LSTM(64, activation='tanh', return_sequences=True ) )\n",
    "model.add( LSTM(128, activation='tanh', return_sequences=True ) )\n",
    "model.add( TimeDistributed( Dense( train_windows[0].shape[0] ) ) )\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8596d76f-c197-4255-9f29-96c0b21d74e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make model\n",
    "\n",
    "fitted_model = model.fit(train_windows_x, train_windows_y, epochs=3, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "plt.plot(fitted_model.history['loss'], label='Training loss')\n",
    "plt.plot(fitted_model.history['val_loss'], label='Validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1074ecb-8334-482d-acb5-2752242a0b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
